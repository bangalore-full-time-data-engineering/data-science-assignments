{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "This assignment serves the purpose of introducing you to the basics of natural language processing and, more specifically, the natural language processing toolkit, [nltk](http://www.nltk.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "Write code to process the [Brown Corpus](http://www.nltk.org/howto/corpus.html) and answer the questions below . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Write a list, named `nouns`, which contains five nouns that are more common in their plural form than their singular form. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brown_tagged_words = brown.tagged_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['years', 'people', 'men', 'eyes', 'days']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "nouns=[x for x,y in brown_tagged_words if y=='NNS']\n",
    "data=Counter(nouns)\n",
    "nouns_mostCommon=data.most_common(5)\n",
    "nouns=[x for x,y in nouns_mostCommon]\n",
    "nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Which word has the greatest number of distinct tags? What are they? Assign this word to the variable `g_word` and print its tag. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that ['WPO', 'CS-NC', 'WPS-NC', 'QL', 'DT', 'WPO-NC', 'WPS-HL', 'DT-NC', 'WPS', 'CS-HL', 'CS', 'NIL']\n"
     ]
    }
   ],
   "source": [
    "data_unique=set(brown_tagged_words)\n",
    "#print(type(brown_tagged_words))\n",
    "from collections import defaultdict\n",
    "res = defaultdict(list)\n",
    "for v, k in data_unique: \n",
    "    res[v].append(k)\n",
    "for v,k in res.items():\n",
    "    if k==max(res.values(), key=len):\n",
    "        g_word=v\n",
    "        print (v,k)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Write a list, `tag_freq`, containing tags in order of decreasing frequency. (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NN',\n",
       " 'IN',\n",
       " 'AT',\n",
       " 'JJ',\n",
       " '.',\n",
       " ',',\n",
       " 'NNS',\n",
       " 'CC',\n",
       " 'RB',\n",
       " 'NP',\n",
       " 'VB',\n",
       " 'VBN',\n",
       " 'VBD',\n",
       " 'CS',\n",
       " 'PPS',\n",
       " 'VBG',\n",
       " 'PP$',\n",
       " 'TO',\n",
       " 'PPSS',\n",
       " 'CD',\n",
       " 'NN-TL',\n",
       " 'MD',\n",
       " 'PPO',\n",
       " 'BEZ',\n",
       " 'BEDZ',\n",
       " 'AP',\n",
       " 'DT',\n",
       " '``',\n",
       " \"''\",\n",
       " 'QL',\n",
       " 'VBZ',\n",
       " 'BE',\n",
       " 'RP',\n",
       " 'WDT',\n",
       " 'HVD',\n",
       " '*',\n",
       " 'WRB',\n",
       " 'BER',\n",
       " 'JJ-TL',\n",
       " 'NP-TL',\n",
       " 'HV',\n",
       " 'WPS',\n",
       " '--',\n",
       " 'BED',\n",
       " 'ABN',\n",
       " 'DTI',\n",
       " 'PN',\n",
       " 'NP$',\n",
       " 'BEN',\n",
       " 'DTS',\n",
       " 'HVZ',\n",
       " ')',\n",
       " '(',\n",
       " 'NNS-TL',\n",
       " 'EX',\n",
       " 'JJR',\n",
       " 'OD',\n",
       " 'NR',\n",
       " ':',\n",
       " 'NN$',\n",
       " 'IN-TL',\n",
       " 'NN-HL',\n",
       " 'DO',\n",
       " 'NPS',\n",
       " 'PPL',\n",
       " 'RBR',\n",
       " 'DOD',\n",
       " 'JJT',\n",
       " 'CD-TL',\n",
       " 'MD*',\n",
       " 'AT-TL',\n",
       " 'ABX',\n",
       " 'BEG',\n",
       " 'NNS-HL',\n",
       " 'UH',\n",
       " '.-HL',\n",
       " 'VBN-TL',\n",
       " 'NP-HL',\n",
       " 'IN-HL',\n",
       " 'DO*',\n",
       " 'PPSS+MD',\n",
       " 'DOZ',\n",
       " 'CD-HL',\n",
       " 'PPS+BEZ',\n",
       " 'DOD*',\n",
       " 'JJ-HL',\n",
       " 'NN$-TL',\n",
       " 'JJS',\n",
       " 'ABL',\n",
       " 'PPLS',\n",
       " 'AT-HL',\n",
       " \"'\",\n",
       " 'NR-TL',\n",
       " 'CC-TL',\n",
       " 'FW-NN',\n",
       " 'HVG',\n",
       " 'WPO',\n",
       " 'PPSS+BER',\n",
       " 'PPSS+BEM',\n",
       " 'QLP',\n",
       " 'NNS$',\n",
       " 'WP$',\n",
       " 'PPSS+HV',\n",
       " 'HVN',\n",
       " 'BEM',\n",
       " 'OD-TL',\n",
       " ')-HL',\n",
       " 'DT+BEZ',\n",
       " 'WQL',\n",
       " ',-HL',\n",
       " 'FW-NN-TL',\n",
       " 'PP$$',\n",
       " '(-HL',\n",
       " 'NIL',\n",
       " 'BEDZ*',\n",
       " 'VBG-HL',\n",
       " 'PPS+MD',\n",
       " 'NP$-TL',\n",
       " ':-HL',\n",
       " 'VBN-HL',\n",
       " 'VBG-TL',\n",
       " 'NN-TL-HL',\n",
       " 'VB-HL',\n",
       " 'CC-HL',\n",
       " 'NN-NC',\n",
       " 'BEZ*',\n",
       " 'EX+BEZ',\n",
       " 'DTX',\n",
       " 'RBT',\n",
       " 'HVD*',\n",
       " 'VB-TL',\n",
       " 'DOZ*',\n",
       " 'PN$',\n",
       " 'FW-IN',\n",
       " 'PPSS+HVD',\n",
       " 'FW-NNS',\n",
       " 'PPS+HVD',\n",
       " 'NNS$-TL',\n",
       " 'FW-JJ-TL',\n",
       " 'VBZ-HL',\n",
       " 'VB+PPO',\n",
       " 'NPS-TL',\n",
       " 'NR$',\n",
       " 'TO-HL',\n",
       " 'FW-JJ',\n",
       " 'RB-HL',\n",
       " 'BER*',\n",
       " 'WDT+BEZ',\n",
       " 'FW-AT-TL',\n",
       " 'PPS+HVZ',\n",
       " 'HV*',\n",
       " 'JJ-NC',\n",
       " 'IN-NC',\n",
       " 'VB-NC',\n",
       " 'AP-HL',\n",
       " 'RB-TL',\n",
       " 'FW-IN-TL',\n",
       " 'NPS$',\n",
       " 'WRB-HL',\n",
       " 'FW-NNS-TL',\n",
       " 'PP$-TL',\n",
       " 'AT-NC',\n",
       " 'NN+BEZ',\n",
       " 'FW-RB',\n",
       " 'PPSS-NC',\n",
       " 'BEZ-HL',\n",
       " 'WDT-HL',\n",
       " 'MD-HL',\n",
       " 'FW-CC',\n",
       " 'FW-VB',\n",
       " 'JJ-TL-HL',\n",
       " 'RB-NC',\n",
       " '---HL',\n",
       " 'NNS-NC',\n",
       " 'CS-HL',\n",
       " 'NP+BEZ',\n",
       " 'PPSS-HL',\n",
       " 'FW-AT',\n",
       " 'BED*',\n",
       " 'HVZ*',\n",
       " ':-TL',\n",
       " 'WPS+BEZ',\n",
       " 'JJS-TL',\n",
       " 'NN$-HL',\n",
       " 'PPS-HL',\n",
       " 'AP-TL',\n",
       " 'FW-IN+AT-TL',\n",
       " 'JJR-HL',\n",
       " 'VBZ-TL',\n",
       " 'CD-TL-HL',\n",
       " 'VBG+TO',\n",
       " 'FW-WDT',\n",
       " 'DOZ-HL',\n",
       " 'NRS',\n",
       " '.-NC',\n",
       " 'VBG-NC',\n",
       " 'UH-TL',\n",
       " 'JJR-TL',\n",
       " 'NP-NC',\n",
       " 'RP-HL',\n",
       " 'NNS-TL-HL',\n",
       " 'FW-CC-TL',\n",
       " 'BE-HL',\n",
       " 'PPO-TL',\n",
       " 'FW-AT+NN-TL',\n",
       " 'TO-NC',\n",
       " 'PP$-NC',\n",
       " 'WPS-TL',\n",
       " 'FW-VBN',\n",
       " 'BER-HL',\n",
       " 'RB+BEZ',\n",
       " 'NR$-TL',\n",
       " 'WRB+BEZ',\n",
       " 'HV-NC',\n",
       " 'VBD-NC',\n",
       " 'NR-HL',\n",
       " 'TO-TL',\n",
       " 'PP$-HL',\n",
       " 'AP$',\n",
       " 'RB$',\n",
       " 'RN',\n",
       " 'FW-PPL',\n",
       " 'PPSS-TL',\n",
       " 'DT-TL',\n",
       " 'WRB-TL',\n",
       " 'FW-NN$',\n",
       " 'PPS-NC',\n",
       " 'VBN-NC',\n",
       " 'PPO-NC',\n",
       " 'BEM*',\n",
       " 'VBD-HL',\n",
       " 'NPS-HL',\n",
       " 'OD-HL',\n",
       " 'MD-TL',\n",
       " '*-HL',\n",
       " 'NP$-HL',\n",
       " 'BEZ-TL',\n",
       " 'WPS+MD',\n",
       " 'FW-UH',\n",
       " 'BEDZ-NC',\n",
       " 'NP-TL-HL',\n",
       " 'MD+HV',\n",
       " 'FW-CD',\n",
       " 'ABN-TL',\n",
       " 'FW-NP',\n",
       " 'FW-VBG',\n",
       " 'DT-NC',\n",
       " 'WRB-NC',\n",
       " 'WDT-NC',\n",
       " 'VBZ-NC',\n",
       " 'PN+BEZ',\n",
       " 'VBN-TL-HL',\n",
       " 'DT-HL',\n",
       " 'JJT-HL',\n",
       " 'VBD-TL',\n",
       " 'DTI-HL',\n",
       " 'BER-TL',\n",
       " 'QL-TL',\n",
       " 'FW-*',\n",
       " 'IN-TL-HL',\n",
       " 'PPS-TL',\n",
       " 'FW-NN-NC',\n",
       " 'FW-PPSS',\n",
       " 'WPS+HVD',\n",
       " 'NP+HVZ',\n",
       " 'WRB+DOD',\n",
       " 'DT$',\n",
       " 'FW-IN+NN',\n",
       " 'CD$',\n",
       " 'JJR-NC',\n",
       " 'PPO-HL',\n",
       " 'DO-TL',\n",
       " 'WQL-TL',\n",
       " 'PN-TL',\n",
       " 'NR-TL-HL',\n",
       " 'AT-TL-HL',\n",
       " 'NN+HVZ',\n",
       " 'VBN+TO',\n",
       " 'BER-NC',\n",
       " 'UH-NC',\n",
       " ',-NC',\n",
       " 'CD-NC',\n",
       " 'RP-NC',\n",
       " 'CC-NC',\n",
       " 'CS-NC',\n",
       " 'BEZ-NC',\n",
       " 'ABN-HL',\n",
       " 'DO-HL',\n",
       " 'NNS$-HL',\n",
       " 'WPO-TL',\n",
       " 'FW-VBZ',\n",
       " 'FW-PPO',\n",
       " 'QL-HL',\n",
       " 'FW-OD-TL',\n",
       " 'HVZ-TL',\n",
       " 'RP-TL',\n",
       " ',-TL',\n",
       " 'FW-NN$-TL',\n",
       " 'FW-BEZ',\n",
       " 'FW-NP-TL',\n",
       " 'JJT-TL',\n",
       " 'EX+MD',\n",
       " 'FW-IN+AT',\n",
       " 'NR-NC',\n",
       " 'VB+TO',\n",
       " 'RP+IN',\n",
       " 'PN+HVZ',\n",
       " 'FW-VB-NC',\n",
       " 'NPS$-TL',\n",
       " 'WRB+BEZ-TL',\n",
       " 'FW-IN+AT-T',\n",
       " 'FW-RB-TL',\n",
       " 'HV-HL',\n",
       " 'VB+IN',\n",
       " 'DO*-HL',\n",
       " 'FW-PP$',\n",
       " 'FW-BER',\n",
       " 'FW-NR-TL',\n",
       " 'FW-CS',\n",
       " 'HV-TL',\n",
       " 'FW-PPO+IN',\n",
       " 'VBN-TL-NC',\n",
       " 'NNS-TL-NC',\n",
       " 'NN-TL-NC',\n",
       " 'BED-NC',\n",
       " 'PPS+BEZ-NC',\n",
       " 'NP+BEZ-NC',\n",
       " 'WPS-NC',\n",
       " 'EX+HVD',\n",
       " 'PN+MD',\n",
       " 'DT+MD',\n",
       " 'HV+TO',\n",
       " 'RB+CS',\n",
       " 'FW-DT',\n",
       " 'PN-HL',\n",
       " 'FW-IN+NN-TL',\n",
       " 'FW-AT+NP-TL',\n",
       " 'BEN-TL',\n",
       " 'CS-TL',\n",
       " 'CC-TL-HL',\n",
       " 'FW-JJ-NC',\n",
       " 'FW-VBD',\n",
       " 'FW-*-TL',\n",
       " 'DTS-HL',\n",
       " 'PN-NC',\n",
       " 'WDT+HVZ',\n",
       " 'FW-IN+NP-TL',\n",
       " 'NN+MD',\n",
       " 'FW-NNS-NC',\n",
       " 'VB+RP',\n",
       " 'FW-PP$-TL',\n",
       " 'DTI-TL',\n",
       " '.-TL',\n",
       " 'FW-NPS',\n",
       " 'FW-CD-TL',\n",
       " 'FW-PPL+VBZ',\n",
       " 'DOZ-TL',\n",
       " 'WDT+BEZ-NC',\n",
       " 'HVZ-NC',\n",
       " 'QL-NC',\n",
       " 'WPS+BEZ-NC',\n",
       " 'PPSS+MD-NC',\n",
       " 'AP-NC',\n",
       " 'DO-NC',\n",
       " 'MD-NC',\n",
       " 'NNS$-NC',\n",
       " 'PPL-NC',\n",
       " 'BEM-NC',\n",
       " 'NPS-NC',\n",
       " 'JJ+JJ-NC',\n",
       " 'WPS-HL',\n",
       " 'FW-DT+BEZ',\n",
       " 'WPS+HVZ',\n",
       " 'MD+TO',\n",
       " 'NN+BEZ-TL',\n",
       " 'EX+HVZ',\n",
       " 'PPSS+VB',\n",
       " 'NNS+MD',\n",
       " 'NP+MD',\n",
       " 'TO+VB',\n",
       " 'VB+AT',\n",
       " 'DTS+BEZ',\n",
       " 'MD*-HL',\n",
       " 'BEDZ-HL',\n",
       " 'PPS+BEZ-HL',\n",
       " 'HVD-HL',\n",
       " 'FW-AT-HL',\n",
       " 'FW-PP$-NC',\n",
       " 'NPS$-HL',\n",
       " 'UH-HL',\n",
       " 'WDT+BEZ-HL',\n",
       " 'PPL-HL',\n",
       " 'FW-VBD-TL',\n",
       " 'PPSS+BER-TL',\n",
       " 'BE-TL',\n",
       " 'PPSS+HV-TL',\n",
       " 'DOD*-TL',\n",
       " 'WDT+BEZ-TL',\n",
       " 'FW-JJR',\n",
       " 'WDT+BER+PP',\n",
       " 'FW-UH-NC',\n",
       " 'RB+BEZ-HL',\n",
       " 'JJS-HL',\n",
       " 'PPL-TL',\n",
       " 'JJR+CS',\n",
       " 'NRS-TL',\n",
       " 'FW-HV',\n",
       " 'DOZ*-TL',\n",
       " 'FW-NPS-TL',\n",
       " '*-TL',\n",
       " 'FW-PN',\n",
       " 'FW-BE',\n",
       " 'FW-PPS',\n",
       " 'FW-NR',\n",
       " 'FW-TO+VB',\n",
       " 'JJ$-TL',\n",
       " 'FW-VB-TL',\n",
       " 'FW-RB+CC',\n",
       " 'FW-WPO',\n",
       " 'FW-NN-TL-NC',\n",
       " 'FW-WPS',\n",
       " 'FW-DTS',\n",
       " 'NNS$-TL-HL',\n",
       " 'FW-VBG-TL',\n",
       " 'EX-HL',\n",
       " 'PPSS+BER-N',\n",
       " 'NP+HVZ-NC',\n",
       " 'DT+BEZ-NC',\n",
       " 'RB+BEZ-NC',\n",
       " '*-NC',\n",
       " 'EX-NC',\n",
       " 'BER*-NC',\n",
       " 'PPSS+BER-NC',\n",
       " 'RBR-NC',\n",
       " 'OD-NC',\n",
       " 'ABN-NC',\n",
       " 'JJT-NC',\n",
       " 'DOD-NC',\n",
       " 'WPO-NC',\n",
       " 'NN+NN-NC',\n",
       " 'AP+AP-NC',\n",
       " 'VB+JJ-NC',\n",
       " 'VB+VB-NC',\n",
       " 'FW-QL',\n",
       " 'JJ-TL-NC',\n",
       " 'FW-JJT',\n",
       " 'WPS+BEZ-TL',\n",
       " 'HVG-HL',\n",
       " 'MD+PPSS',\n",
       " 'NR+MD',\n",
       " 'NN+IN',\n",
       " 'NN+HVD-TL',\n",
       " 'WDT+DOD',\n",
       " 'WRB+DO',\n",
       " 'WRB+IN',\n",
       " 'WRB+MD',\n",
       " 'NN+HVZ-TL',\n",
       " 'WRB+BER',\n",
       " 'PPSS+BEZ',\n",
       " 'PPSS+BEZ*',\n",
       " 'RBR+CS',\n",
       " 'IN+PPO',\n",
       " 'IN+IN',\n",
       " 'DO+PPSS',\n",
       " 'WRB+DOZ',\n",
       " 'WDT+DO+PPS',\n",
       " 'WRB+DOD*',\n",
       " 'WDT+BER',\n",
       " 'FW-OD-NC',\n",
       " 'FW-PPSS+HV',\n",
       " 'PN+HVD',\n",
       " 'FW-UH-TL']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags=[y for x,y in brown_tagged_words ]\n",
    "tag_frequency=Counter(tags)\n",
    "tag_frequency.most_common()\n",
    "tag_freq=[x for x,y in tag_frequency.most_common()]\n",
    "tag_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "In this part of the assignment, use the `nltk` to find the parts of speech of the sentences below. You should use three taggers to compare the different results: `pos_tag`, `UnigramTagger`, and `BiGramTagger`. Use a multi-line comment to answer the following for each example: (6 points)\n",
    "\n",
    "*Were there any mislabeled tags in any of the word tagger results? Did the three taggers tag words differently? If so, how?* (3 points each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \"The boat is going to sink and I am scared!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'boat', 'is', 'going', 'to', 'sink', 'and', 'I', 'am', 'scared', '!']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nanswer to qualitative question goes here!\\n'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code goes below\n",
    "sent=\"The boat is going to sink and I am scared!\"\n",
    "words=nltk.word_tokenize(sent)\n",
    "print(words)\n",
    "nltk.\n",
    "\"\"\"\n",
    "answer to qualitative question goes here!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. \"I had a dream that I found a lost dog and instead of taking it to its rightful owner, I brought it home and kept it.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# code goes below\n",
    "\n",
    "\"\"\"\n",
    "answer to qualitative question goes here!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. \"I'm procrastinating my code for this assignment!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# code goes below\n",
    "\n",
    "\"\"\"\n",
    "answer to qualitative question goes here!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do you think different word taggers *would* obtain different tags for the same word? Explain your answer in the markdown cell below. (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you think stemming words would affect the variance-bias in word tagging? Explain your answer in the markdown cell below. (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 \n",
    "\n",
    "This part will require that you write functions to normalize and stem a given input. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `normalize()` that takes a string of text as input and returns a list of tokenized words in lower case format. You should not use built-in functions from `nltk` or any other natural language processing modules. (6 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how', 'are', 'you', '?']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write normalize() below\n",
    "def normalize(sent):\n",
    "    lst=sent.split()\n",
    "    lst=list(map(lambda x:x.lower(),lst))\n",
    "    return lst\n",
    "normalize(\"How are you ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `stem()` that takes a list of normalized words as input and returns **two** lists of the stemmed words -- one using the Lancaster Stemmer, the other using the Porter Stemmer. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write stem() below\n",
    "def stem(normalized):\n",
    "    lancaster = nltk.LancasterStemmer()\n",
    "    stems_lancaster = [lancaster.stem(i) for i in normalized]\n",
    "    porter = nltk.PorterStemmer()\n",
    "    stems_porter = [porter.stem(i) for i in normalized]\n",
    "    return stems_lancaster,stems_porter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['how', 'ar', 'you', '?'], ['how', 'are', 'you', '?'])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem(['how', 'are', 'you', '?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
